{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"__typename\":\"Tweet\",\"in_reply_to_screen_name\":\"Sol__Yumruk\",\"in_reply_to_status_id_str\":\"1663984481437401105\",\"in_reply_to_user_id_str\":\"2917028536\",\"lang\":\"tr\",\"favorite_count\":0,\"created_at\":\"2023-05-31T20:59:54.000Z\",\"display_text_range\":[13,51],\"entities\":{\"hashtags\":[],\"urls\":[],\"user_mentions\":[{\"id_str\":\"2917028536\",\"indices\":[0,12],\"name\":\"Sol Yumruk\",\"screen_name\":\"Sol__Yumruk\"}],\"symbols\":[]},\"id_str\":\"1664013858292346881\",\"text\":\"@Sol__Yumruk 2 sene Ã§ok.Bu gidiÅŸle 6 ayÄ± zor gÃ¶rÃ¼r.\",\"user\":{\"id_str\":\"3391907170\",\"name\":\"GÃ¼l\",\"profile_image_url_https\":\"https://pbs.twimg.com/profile_images/1654189008019247121/QLFPdGEr_normal.jpg\",\"screen_name\":\"gul741502\",\"verified\":false,\"is_blue_verified\":false,\"profile_image_shape\":\"Circle\"},\"edit_control\":{\"edit_tweet_ids\":[\"1664013858292346881\"],\"editable_until_msecs\":\"1685568594000\",\"is_edit_eligible\":false,\"edits_remaining\":\"5\"},\"conversation_count\":0,\"news_action_type\":\"conversation\",\"parent\":{\"lang\":\"tr\",\"reply_count\":4472,\"retweet_count\":745,\"favorite_count\":11195,\"possibly_sensitive\":false,\"created_at\":\"2023-05-31T19:03:10.000Z\",\"display_text_range\":[0,82],\"entities\":{\"hashtags\":[],\"urls\":[],\"user_mentions\":[],\"symbols\":[],\"media\":[{\"display_url\":\"pic.twitter.com/SaekxwN4KM\",\"expanded_url\":\"https://twitter.com/Sol__Yumruk/status/1663984481437401105/photo/1\",\"indices\":[83,106],\"url\":\"https://t.co/SaekxwN4KM\"}]},\"id_str\":\"1663984481437401105\",\"text\":\"KÄ±lÄ±Ã§daroÄŸlu istifa etmesin, 2 sene sonra CumhurbaÅŸkanÄ±! \\nBu twitt burada kalsÄ±nâ€¦. https://t.co/SaekxwN4KM\",\"user\":{\"id_str\":\"2917028536\",\"name\":\"Sol Yumruk\",\"profile_image_url_https\":\"https://pbs.twimg.com/profile_images/1451174005449363459/6g1SrWhY_normal.jpg\",\"screen_name\":\"Sol__Yumruk\",\"verified\":false,\"is_blue_verified\":true,\"profile_image_shape\":\"Circle\"},\"edit_control\":{\"edit_tweet_ids\":[\"1663984481437401105\"],\"editable_until_msecs\":\"1685561590000\",\"is_edit_eligible\":true,\"edits_remaining\":\"5\"},\"mediaDetails\":[{\"display_url\":\"pic.twitter.com/SaekxwN4KM\",\"expanded_url\":\"https://twitter.com/Sol__Yumruk/status/1663984481437401105/photo/1\",\"ext_media_availability\":{\"status\":\"Available\"},\"indices\":[83,106],\"media_url_https\":\"https://pbs.twimg.com/media/FxepELOWwCYoBng.jpg\",\"original_info\":{\"height\":554,\"width\":554,\"focus_rects\":[{\"x\":0,\"y\":80,\"w\":554,\"h\":310},{\"x\":0,\"y\":0,\"w\":554,\"h\":554},{\"x\":20,\"y\":0,\"w\":486,\"h\":554},{\"x\":125,\"y\":0,\"w\":277,\"h\":554},{\"x\":0,\"y\":0,\"w\":554,\"h\":554}]},\"sizes\":{\"large\":{\"h\":554,\"resize\":\"fit\",\"w\":554},\"medium\":{\"h\":554,\"resize\":\"fit\",\"w\":554},\"small\":{\"h\":554,\"resize\":\"fit\",\"w\":554},\"thumb\":{\"h\":150,\"resize\":\"crop\",\"w\":150}},\"type\":\"photo\",\"url\":\"https://t.co/SaekxwN4KM\"}],\"photos\":[{\"backgroundColor\":{\"red\":204,\"green\":214,\"blue\":221},\"cropCandidates\":[{\"x\":0,\"y\":80,\"w\":554,\"h\":310},{\"x\":0,\"y\":0,\"w\":554,\"h\":554},{\"x\":20,\"y\":0,\"w\":486,\"h\":554},{\"x\":125,\"y\":0,\"w\":277,\"h\":554},{\"x\":0,\"y\":0,\"w\":554,\"h\":554}],\"expandedUrl\":\"https://twitter.com/Sol__Yumruk/status/1663984481437401105/photo/1\",\"url\":\"https://pbs.twimg.com/media/FxepELOWwCYoBng.jpg\",\"width\":554,\"height\":554}],\"isEdited\":false,\"isStaleEdit\":false},\"isEdited\":false,\"isStaleEdit\":false}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://cdn.syndication.twimg.com/tweet-result\"\n",
    "\n",
    "querystring = {\"id\":\"1664013858292346881\",\"lang\":\"en\", \"token\":\"x\"}\n",
    "\n",
    "payload = \"\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/114.0\",\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Origin\": \"https://platform.twitter.com\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Referer\": \"https://platform.twitter.com/\",\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"cross-site\",\n",
    "    \"Pragma\": \"no-cache\",\n",
    "    \"Cache-Control\": \"no-cache\",\n",
    "    \"TE\": \"trailers\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of CSV files: 25779\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Replace 'your_main_folder_path' with the path to your main folder\n",
    "csv_files = glob.glob('../data/output/**/*.csv', recursive=True)\n",
    "number_of_csv_files = len(csv_files)\n",
    "print(f\"Total number of CSV files: {number_of_csv_files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1500.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1901.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1958.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_889.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1980.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1047.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1682.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157895/1661650135.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, usecols=['text'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_2585.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_909.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_675.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1109.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetids_2023-05_splitted/output_streamV2_tweetids_2023-05_1319.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_1473.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_1307.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_271.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_2027.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-11_splitted/output_stream_tweetids_2022-11_75.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-11_splitted/output_stream_tweetids_2022-11_420.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_176.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_112.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_177.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2023-01_splitted/output_stream_tweetids_2023-01_846.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetids_2023-03_splitted/output_streamV2_tweetids_2023-03_675.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_473.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_1431.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_1397.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_896.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_719.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Number of files with non-empty 'text' entries: 25750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_non_empty_text(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=['text'])\n",
    "        if not df['text'].dropna().empty:\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "    return False\n",
    "\n",
    "non_empty_text_files = sum(check_non_empty_text(file) for file in csv_files)\n",
    "print(f\"Number of files with non-empty 'text' entries: {non_empty_text_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1500.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1901.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1958.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_889.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1980.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1047.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1682.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_157895/1906871542.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, usecols=['text'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_2585.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_909.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_675.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1109.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetids_2023-05_splitted/output_streamV2_tweetids_2023-05_1319.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_1473.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_1307.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_271.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_2027.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-11_splitted/output_stream_tweetids_2022-11_75.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-11_splitted/output_stream_tweetids_2022-11_420.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_176.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_112.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_177.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/stream_tweetids_2023-01_splitted/output_stream_tweetids_2023-01_846.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetids_2023-03_splitted/output_streamV2_tweetids_2023-03_675.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_473.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_1431.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_1397.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_896.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_719.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Total number of non-empty 'text' entries across all files: 67612146\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_non_empty_text(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=['text'])\n",
    "        non_empty_df = df.dropna(subset=['text'])\n",
    "        return len(non_empty_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Assuming csv_files is a list of your CSV file paths\n",
    "non_empty_counts = [count_non_empty_text(file) for file in csv_files]\n",
    "\n",
    "# To get the total number of non-empty text entries across all files\n",
    "total_non_empty = sum(non_empty_counts)\n",
    "print(f\"Total number of non-empty 'text' entries across all files: {total_non_empty}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following to calculate the average of the extracted data per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 2022-08, Number of files: 720, Non-empty 'text' entries: 3364806\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get a list of all CSV files\n",
    "# csv_files = glob.glob('../data/output/**/*.csv', recursive=True)\n",
    "csv_files = glob.glob('../data/output/missing_tweets/2_stream_tweetids_2022-08_splitted/*.csv', recursive=True)\n",
    "\n",
    "# Function to extract month from file path\n",
    "def extract_month(file_path):\n",
    "    match = re.search(r'(\\d{4}-\\d{2})', file_path)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Group files by month\n",
    "files_by_month = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    month = extract_month(file)\n",
    "    if month:\n",
    "        files_by_month[month].append(file)\n",
    "\n",
    "# Function to count non-empty text entries in a file\n",
    "def count_non_empty_text(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=['text'])\n",
    "        non_empty_df = df.dropna(subset=['text'])\n",
    "        return len(non_empty_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Count files and entries for each month\n",
    "for month, files in files_by_month.items():\n",
    "    non_empty_counts = [count_non_empty_text(file) for file in files]\n",
    "    total_non_empty = sum(non_empty_counts)\n",
    "    print(f\"Month: {month}, Number of files: {len(files)}, Non-empty 'text' entries: {total_non_empty}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new method to find out tweet numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Get a list of all CSV files\n",
    "# csv_files = glob.glob('../data/output/**/*.csv', recursive=True)\n",
    "csv_files = glob.glob('../data/output/missing_tweets/2_stream_tweetids_2022-09_splitted/*.csv', recursive=True)\n",
    "\n",
    "# Function to extract month from file path\n",
    "def extract_month(file_path):\n",
    "    match = re.search(r'(\\d{4}-\\d{2})', file_path)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Group files by month\n",
    "files_by_month = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    month = extract_month(file)\n",
    "    if month:\n",
    "        files_by_month[month].append(file)\n",
    "\n",
    "# Function to count rows where only tweet_id is present (assuming other fields are missing)\n",
    "def count_tweet_id_only(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, usecols=['tweet_id', 'text', 'tweet_type'])  # Include other fields as necessary\n",
    "        incomplete_tweets = df[df['tweet_id'].notna() & df['text'].isna()]  # Adjust based on which fields indicate incomplete data\n",
    "        return len(incomplete_tweets), len(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file ../data/output/missing_tweets/2_stream_tweetids_2022-09_splitted/output_output_stream_tweetids_2022-09_448.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error processing file ../data/output/missing_tweets/2_stream_tweetids_2022-09_splitted/output_output_stream_tweetids_2022-09_800.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Month: 2022-09, Number of files: 833, Incomplete tweet entries: 1646042, complete tweet entries: 6991265\n"
     ]
    }
   ],
   "source": [
    "# Count files and entries for each month\n",
    "for month, files in files_by_month.items():\n",
    "    incomplete_tweet_counts = [count_tweet_id_only(file) for file in files]\n",
    "    total_incomplete = sum(count[0] for count in incomplete_tweet_counts)\n",
    "    total_missing = sum(count[1] for count in incomplete_tweet_counts)\n",
    "    print(f\"Month: {month}, Number of files: {len(files)}, Incomplete tweet entries: {total_incomplete}, total_missing tweet entries: {total_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweety import Twitter\n",
    "import datetime\n",
    "\n",
    "app = Twitter(\"session\")\n",
    "\n",
    "def fetch_additional_info(app, tweet_id):\n",
    "    try:\n",
    "        tweet = app.tweet_detail(f\"https://twitter.com/dbdevletbahceli/status/{tweet_id}\")\n",
    "    except Exception as e:\n",
    "        # logging.error(f\"An error occurred scraping {tweet_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "    return tweet\n",
    "\n",
    "# Extract the additional info from API response\n",
    "def parse_api_response(tweet):\n",
    "    if tweet is None:\n",
    "        return {\n",
    "        'tweet_id': '',\n",
    "        'tweet_type': \"deleted\",\n",
    "        'hashtags': [],\n",
    "        'mentions': mentions,\n",
    "        'lang': lang,\n",
    "        'favorite_count': favorite_count,\n",
    "        'created_at': created_at,\n",
    "        'text': text,\n",
    "        'parent_tweet_id': parent_tweet_id,         \n",
    "    }\n",
    "    \n",
    "    # Extracting data directly from the tweet object\n",
    "    lang = getattr(tweet, 'language', '')\n",
    "    favorite_count = getattr(tweet, 'likes', 0)  # Assuming favorite_count is a property\n",
    "    \n",
    "    created_at = getattr(tweet, 'created_on', None)\n",
    "    if isinstance(created_at, datetime.datetime):\n",
    "        created_at = created_at.strftime('%Y-%m-%d %H:%M:%S %Z')    \n",
    "    \n",
    "    text = getattr(tweet, 'text', '')\n",
    "    tweet_id = getattr(tweet, 'id', '')\n",
    "\n",
    "    # New:\n",
    "    # Assuming hashtags are stored in a list of hashtag objects within the tweet object\n",
    "    hashtags = [hashtag[\"text\"] for hashtag in getattr(tweet, 'hashtags', [])]    \n",
    "    mentions = getattr(tweet, 'user_mentions', [])\n",
    "    mentions_data = [{'id': getattr(user, 'id', ''), 'name': getattr(user, 'name', '')} for user in mentions]    \n",
    "    parent_tweet_id = getattr(tweet, 'replied_to', '')\n",
    "    # tweet_type = parsed_data.get('__typename', '')\n",
    "\n",
    "    return {\n",
    "        'tweet_id': tweet_id,\n",
    "        'tweet_type': \"Tweet\",\n",
    "        'hashtags': hashtags,\n",
    "        'mentions': mentions_data,\n",
    "        'lang': lang,\n",
    "        'favorite_count': favorite_count,\n",
    "        'created_at': created_at,\n",
    "        'text': text,\n",
    "        'parent_tweet_id': parent_tweet_id,         \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet_id': '1633925544310915077',\n",
       " 'tweet_type': 'Tweet',\n",
       " 'hashtags': ['UzmanÃ‡avuÅŸlaraKadro'],\n",
       " 'mentions': [{'id': '232342448', 'name': 'Ali Tilkici ðŸ‡¹ðŸ‡·'},\n",
       "  {'id': '68034431', 'name': 'Recep Tayyip ErdoÄŸan'},\n",
       "  {'id': '425441195', 'name': 'Vedat Bilgin'},\n",
       "  {'id': '214017108', 'name': 'Devlet BahÃ§eli'}],\n",
       " 'lang': 'tr',\n",
       " 'favorite_count': 2,\n",
       " 'created_at': '2023-03-09 20:19:41 UTC',\n",
       " 'text': '@alitilkici38\\n#UzmanÃ‡avuÅŸlaraKadro\\n@RTErdogan \\n@vedatbilgn\\n@dbdevletbahceli TÃ¼rk ordusunun neferlerine kadro helal degilmidir ?',\n",
       " 'parent_tweet_id': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = fetch_additional_info(app, tweet_id=\"1633925544310915077\")\n",
    "parse_api_response(tweet)\n",
    "\n",
    "# print(tweet)\n",
    "# print(tweet.text)\n",
    "# print(tweet.created_on)\n",
    "# print(tweet.language)\n",
    "# # print(tweet.hashtags[0][\"text\"])\n",
    "# print(tweet.hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call\n",
    "import logging\n",
    "import requests\n",
    "def fetch_additional_info_old(tweet_id):\n",
    "    url = \"https://cdn.syndication.twimg.com/tweet-result\"\n",
    "    querystring = {\"id\": tweet_id, \"lang\": \"en\", \"token\": \"x\"}\n",
    "    payload = \"\"\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/114.0\",\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Origin\": \"https://platform.twitter.com\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Referer\": \"https://platform.twitter.com/\",\n",
    "    \"Sec-Fetch-Dest\": \"empty\",\n",
    "    \"Sec-Fetch-Mode\": \"cors\",\n",
    "    \"Sec-Fetch-Site\": \"cross-site\",\n",
    "    \"Pragma\": \"no-cache\",\n",
    "    \"Cache-Control\": \"no-cache\",\n",
    "    \"TE\": \"trailers\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "        if response.status_code != 200:\n",
    "            print(f'Failed to fetch additional info for tweet_id {tweet_id}. Here is the response: {response.text}')\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logging.error(f'Failed to fetch additional info for tweet_id {tweet_id}')\n",
    "        return None\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch additional info for tweet_id 1550617637838884868. Here is the response: <!DOCTYPE html>\n",
      "<html lang=\"en\" class=\"dog\">\n",
      "  <head>\n",
      "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>X / ?</title>\n",
      "    <meta name=\"version\" content=\"1\">\n",
      "    <link href=\"https://abs.twimg.com/favicons/twitter.3.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
      "    <link rel=\"stylesheet\" href=\"https://abs.twimg.com/errors/fullscreen_errors-047ca1475a6efac7c9c89a9ff92b7a20.css\">\n",
      "  </head>\n",
      "  <body dir=\"auto\">\n",
      "    <div class=\"top\">\n",
      "      <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 1519 200\">\n",
      "        <defs/>\n",
      "        <path d=\"M708 103l9-5 13 1 2-2 5 1h8l1-1 42-5h7l7 3v1l12-2a9368 9368 0 0129-6l2-5 12 1 6-2 3 1 2 1v-2l13-2v1l4 2 7-1h1l17-3 1 2 4-1 18-7 3-1 4-1h9l13-1 1-4 3-2 13 1v2l22-2 10-3h6l10 5 16-5 15-3 2-1 8-4 6-2 12-1 7-2 8 5 7 1 22-9h7l5-1v-1l25-3 1 2 5 2v1h11l2 1 8-4h3l-1 1h11l10-6 6 3 9-1 4-1 1 1 1-2 6-1 1-1 10-2h2l7-5v1h4l3-1c11 0 23 2 34-3 2-2 7 0 10 0l12 1 4 1 9 2 12-1 11-3 11 1h4l10-6 17 1 2 1c9 2 19-3 22-11l1-1 9 1 15-5c3-1 9 4 9-5 5 0 5 3 5 7l2 3 4-1 4-2 9-4 3-3h3l8-4 6-3 26 2 7-4h18l7 1c10 3 13-6 17-12l8 4 3-1 14-3 15-2a38 38 0 01-5-1l-8-4 7-8 8-4-10-136-922 71 16 205z\"/>\n",
      "        <path d=\"M-36 193l9-5 13 1 2-2 5 1h8l1-1 42-5h7l7 3v1l12-2a9328 9328 0 0129-6l2-5 12 1 6-2 3 1 2 1v-2l13-2v1l4 2 7-1h1l17-3 1 2 4-1 18-7 3-1 4-1h9l13-1 1-4 3-2 13 1v2l22-2 10-3h6l10 5 16-5 15-3 2-1 8-4 6-2 12-1 7-2 8 5 7 1 22-9h7l5-1v-1l25-3 1 2 5 2v1h11l2 1 8-4h3l-1 1h9a6 6 0 002 0l10-6 6 3 9-1 4-1a6 6 0 001 1l1-2 6-1 1-1 10-2h2l7-5v1h4l3-1c11 0 23 2 34-3 2-2 7 0 10 0l12 1 4 1 9 2 12-1 11-3 11 1h4l10-6 17 1 2 1c9 2 19-3 22-11l1-1 9 1 15-5c3-1 9 4 9-5 5 0 5 3 5 7l2 3 4-1 4-2 9-4 3-3h3l8-4 6-3 26 2 7-4h18l7 1c10 3 13-6 17-12l8 4 3-1 14-3 15-2a37 37 0 01-5-1l-8-4 7-8 8-4-10-136-922 71 16 205z\"/>\n",
      "      </svg>\n",
      "    </div>\n",
      "    <div class=\"container\">\n",
      "      <div class=\"content\">\n",
      "        <a href=\"https://twitter.com\" title=\"X logo\">\n",
      "          <svg viewBox=\"0 0 24 24\" aria-hidden=\"true\" class=\"x-logo\"><g><path d=\"M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z\"></path></g></svg>\n",
      "        </a>\n",
      "        <h1 id=\"header\">Nothing to see here</h1>\n",
      "        <p id=\"description\">Looks like this page doesnâ€™t exist. Hereâ€™s a picture of a poodle sitting in a chair for your trouble.</p>\n",
      "\n",
      "          <a id=\"button_search\" href=\"/\" class=\"button\">Looking for this?</a>\n",
      "\n",
      "      </div>\n",
      "      <img id=\"image\" src=\"https://abs.twimg.com/errors/ErrorState_NotFound.png\" alt=\"A primped poodle with a bow in its hair sitting in a chair like a human.\">\n",
      "      <div class=\"footer\">\n",
      "        <ul>\n",
      "          <li><a href=\"https://twitter.com/\" id=\"footer_home\">Home</a></li>\n",
      "          <li><a href=\"https://status.twitterstat.us/\" id=\"footer_status\">Status</a></li>\n",
      "          <li><a href=\"https://twitter.com/tos\" id=\"footer_tos\">Terms of Service</a></li>\n",
      "          <li><a href=\"https://twitter.com/privacy\" id=\"footer_privacy\">Privacy Policy</a></li>\n",
      "          <li><a href=\"https://support.twitter.com/articles/20170514\" id=\"footer_cookie\">Cookie Policy</a></li>\n",
      "          <li><a href=\"https://legal.twitter.com/imprint\" id=\"footer_imprint\">Imprint</a></li>\n",
      "          <li><a href=\"https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html\" id=\"footer_ads\">Ads info</a></li>\n",
      "          <li dir=\"ltr\">&copy; X Corp. <span id=\"copyright-year\">&emsp;&emsp;&emsp;&emsp;</span></li>\n",
      "        </ul>\n",
      "      </div>\n",
      "    </div>\n",
      "  </body>\n",
      "  <script src=\"https://abs.twimg.com/errors/404-8651f633fd193e0b546010676a4fac06.js\"></script>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fetch_additional_info_old(tweet_id=\"1550617637838884868\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = \"1633925544310915077\"\n",
    "url = f\"https://cdn.syndication.twimg.com/tweet-result?features=tfw_timeline_list%3A%3Btfw_follower_count_sunset%3Atrue%3Btfw_tweet_edit_backend%3Aon%3Btfw_refsrc_session%3Aon%3Btfw_fosnr_soft_interventions_enabled%3Aon%3Btfw_mixed_media_15897%3Atreatment%3Btfw_experiments_cookie_expiration%3A1209600%3Btfw_show_birdwatch_pivots_enabled%3Aon%3Btfw_duplicate_scribes_to_settings%3Aon%3Btfw_use_profile_image_shape_enabled%3Aon%3Btfw_video_hls_dynamic_manifests_15082%3Atrue_bitrate%3Btfw_legacy_timeline_sunset%3Atrue%3Btfw_tweet_edit_frontend%3Aon&id={tweet_id}&lang=en&token=14fxvks611f&221so0=njalwq8t7y59&z6mce9=s45s368ppey&1fagww=1f0mdbv8d6w9&p53rza=npya5r8z6gpn&hhiabv=5c4h87iskbds&4yis9c=1198gk8pbc6bo\"\n",
    "response = requests.request(\"GET\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"__typename\":\"Tweet\",\"in_reply_to_screen_name\":\"alitilkici38\",\"in_reply_to_user_id_str\":\"232342448\",\"lang\":\"tr\",\"favorite_count\":2,\"created_at\":\"2023-03-09T20:19:41.000Z\",\"display_text_range\":[0,127],\"entities\":{\"hashtags\":[{\"indices\":[14,34],\"text\":\"UzmanÃ‡avuÅŸlaraKadro\"}],\"urls\":[],\"user_mentions\":[{\"id_str\":\"232342448\",\"indices\":[0,13],\"name\":\"Ali Tilkici ðŸ‡¹ðŸ‡·\",\"screen_name\":\"alitilkici38\"},{\"id_str\":\"68034431\",\"indices\":[35,45],\"name\":\"Recep Tayyip ErdoÄŸan\",\"screen_name\":\"RTErdogan\"},{\"id_str\":\"425441195\",\"indices\":[47,58],\"name\":\"Vedat Bilgin\",\"screen_name\":\"vedatbilgn\"},{\"id_str\":\"214017108\",\"indices\":[59,75],\"name\":\"Devlet BahÃ§eli\",\"screen_name\":\"dbdevletbahceli\"}],\"symbols\":[]},\"id_str\":\"1633925544310915077\",\"text\":\"@alitilkici38\\\\n#UzmanÃ‡avuÅŸlaraKadro\\\\n@RTErdogan \\\\n@vedatbilgn\\\\n@dbdevletbahceli TÃ¼rk ordusunun neferlerine kadro helal degilmidir ?\",\"user\":{\"id_str\":\"1613195739479277568\",\"name\":\"mhmmt44\",\"profile_image_url_https\":\"https://pbs.twimg.com/profile_images/1645185983623622658/4Ko47aFb_normal.jpg\",\"screen_name\":\"mhmmt4444\",\"verified\":false,\"is_blue_verified\":false,\"profile_image_shape\":\"Circle\"},\"edit_control\":{\"edit_tweet_ids\":[\"1633925544310915077\"],\"editable_until_msecs\":\"1678394981000\",\"is_edit_eligible\":true,\"edits_remaining\":\"5\"},\"conversation_count\":0,\"news_action_type\":\"conversation\",\"isEdited\":false,\"isStaleEdit\":false}'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test getting the missing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import logging\n",
    "def get_missing_tweet_ids(output_folder):\n",
    "    logging.info(f'Getting missing tweet ids for folder: {output_folder}')\n",
    "    missing_tweet_ids = []\n",
    "\n",
    "    for file_name in os.listdir(output_folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(output_folder, file_name)\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, dtype={'tweet_id': 'Int64'}, usecols=['tweet_id', 'text', 'tweet_type'])\n",
    "                \n",
    "                # Check if required columns are present\n",
    "                if 'text' in df.columns and 'tweet_type' in df.columns:\n",
    "                    # Filter out rows with empty 'text' or 'tweet_type'\n",
    "                    missing_tweets = df[df['text'].isna() & df['tweet_id'].notna()]['tweet_id']\n",
    "                    missing_tweet_ids.extend(missing_tweets.tolist())\n",
    "                else:\n",
    "                    logging.warning(f\"File {file_name} does not contain required columns.\")\n",
    "                    \n",
    "            except FileNotFoundError:\n",
    "                logging.error(f\"File {file_path} not found.\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                logging.warning(f\"No data in file {file_path}.\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return missing_tweet_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error processing file ../data/output/missing_tweets/2_stream_tweetids_2022-11_splitted/output_output_stream_tweetids_2022-11_619.csv: Unable to parse string \"ðŸ“¢Luxell Lxaf-01 Fast Fryer XXL 7.5 Litre ( YaÄŸsÄ±z Hava FritÃ¶zÃ¼ / Airfryer ) New Series\" at position 5934\n"
     ]
    }
   ],
   "source": [
    "output_folder = '../data/output/missing_tweets/2_stream_tweetids_2022-11_splitted'  # Update this with your folder path\n",
    "missing_tweet_ids = get_missing_tweet_ids(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5588880"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_tweet_ids_from_file(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, dtype={'tweet_id': 'Int64'}, usecols=['tweet_id', 'text', 'tweet_type'])\n",
    "        # Filter out rows with empty 'text' or other critical fields\n",
    "        missing_tweets = df[df['text'].isna() & df['tweet_id'].notna()]['tweet_id']\n",
    "        return missing_tweets.to_list()\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {file_path}\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logging.warning(f\"No data in file: {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1550594271014780931,\n",
       " 1550594272252100608,\n",
       " 1550594275217399809,\n",
       " 1550594276022796289,\n",
       " 1550594276924575746,\n",
       " 1550594284365152260,\n",
       " 1550594284830838787,\n",
       " 1550594289041903625,\n",
       " 1550594289037606913,\n",
       " 1550594291877257222,\n",
       " 1550594290711236610,\n",
       " 1550594296411082752,\n",
       " 1550594293378809857,\n",
       " 1550594300177776640,\n",
       " 1550594304929824769,\n",
       " 1550594302841180163,\n",
       " 1550594304321667075,\n",
       " 1550594305827422209,\n",
       " 1550594306901155849,\n",
       " 1550594307509329920,\n",
       " 1550594307417047041,\n",
       " 1550594312106348544,\n",
       " 1550594311057727489,\n",
       " 1550594311313657858,\n",
       " 1550594315554099216,\n",
       " 1550594316908773376,\n",
       " 1550594317135355905,\n",
       " 1550594322134974465,\n",
       " 1550594323527438337,\n",
       " 1550594322868887564,\n",
       " 1550594333107261444,\n",
       " 1550594331320410114,\n",
       " 1550594331647639553,\n",
       " 1550594338782154758,\n",
       " 1550594335577710593,\n",
       " 1550594337226035203,\n",
       " 1550594339369373706,\n",
       " 1550594342909349895,\n",
       " 1550594342947065857,\n",
       " 1550594346377945088,\n",
       " 1550594344633114624,\n",
       " 1550594348835897344,\n",
       " 1550594354087137280,\n",
       " 1550594354560974848,\n",
       " 1550594352946286593,\n",
       " 1550594358453354500,\n",
       " 1550594355949457408,\n",
       " 1550594357845282822,\n",
       " 1550594362022715392,\n",
       " 1550594362047881220,\n",
       " 1550594367823429632,\n",
       " 1550594368389668868,\n",
       " 1550594370952372224,\n",
       " 1550594369631158274,\n",
       " 1550594370847514625,\n",
       " 1550594370411417606,\n",
       " 1550594374563762177,\n",
       " 1550594376732139520,\n",
       " 1550594374156763136,\n",
       " 1550594377973698561,\n",
       " 1550594384651075587,\n",
       " 1550594384688828417,\n",
       " 1550594383824789504,\n",
       " 1550594390464274432,\n",
       " 1550594391412187142,\n",
       " 1550594392087478273,\n",
       " 1550594393777881089,\n",
       " 1550594393693999111,\n",
       " 1550594394297958400,\n",
       " 1550594398051868675,\n",
       " 1550594404808904704,\n",
       " 1550594406947950594,\n",
       " 1550594410219544579,\n",
       " 1550594408113995778,\n",
       " 1550594412786454535,\n",
       " 1550594413214289920,\n",
       " 1550594410957754370,\n",
       " 1550594414594199553,\n",
       " 1550594413834936324,\n",
       " 1550594411968471040,\n",
       " 1550594417341480965,\n",
       " 1550594419438534656,\n",
       " 1550594421594505217,\n",
       " 1550594422047444995,\n",
       " 1550594426497638400,\n",
       " 1550594422861168641,\n",
       " 1550594423263842308,\n",
       " 1550594422890500096,\n",
       " 1550594430809346048,\n",
       " 1550594430767333378,\n",
       " 1550594431056764935,\n",
       " 1550594433116250112,\n",
       " 1550594431316856832,\n",
       " 1550594439680344069,\n",
       " 1550594445053247490,\n",
       " 1550594445950783488,\n",
       " 1550594444780617729,\n",
       " 1550594449750761473,\n",
       " 1550594448412889089,\n",
       " 1550594449092366337,\n",
       " 1550594452187652096,\n",
       " 1550594454125420546,\n",
       " 1550594458911137792,\n",
       " 1550594457241780225,\n",
       " 1550594458772725760,\n",
       " 1550594464393093120,\n",
       " 1550594472760774659,\n",
       " 1550594471695368199,\n",
       " 1550594476472664065,\n",
       " 1550594477387091976,\n",
       " 1550594477353537539,\n",
       " 1550594474857873408,\n",
       " 1550594478821572608,\n",
       " 1550594482210488321,\n",
       " 1550594482357374980,\n",
       " 1550594482932006912,\n",
       " 1550594490775257090,\n",
       " 1550594492746665984,\n",
       " 1550594492700545030,\n",
       " 1550594495351328781,\n",
       " 1550594495829385217,\n",
       " 1550594496634802177,\n",
       " 1550594496144052225,\n",
       " 1550594501231648770,\n",
       " 1550594497788219393,\n",
       " 1550594502284419074,\n",
       " 1550594498828402695,\n",
       " 1550594505862254593,\n",
       " 1550594509209313282,\n",
       " 1550594514267635712,\n",
       " 1550594513395236882,\n",
       " 1550594515941089283,\n",
       " 1550594516352212992,\n",
       " 1550594520227741697,\n",
       " 1550594519741104132,\n",
       " 1550594526468784129,\n",
       " 1550594525994827776,\n",
       " 1550594530663141378,\n",
       " 1550594530604457985,\n",
       " 1550594531892109312,\n",
       " 1550594533574033410,\n",
       " 1550594543195750401,\n",
       " 1550594543602569219,\n",
       " 1550594544156172289,\n",
       " 1550594545343143939,\n",
       " 1550594546177826817,\n",
       " 1550594551173332992,\n",
       " 1550594550800027649,\n",
       " 1550594551617839105,\n",
       " 1550594549361385473,\n",
       " 1550594555426312192,\n",
       " 1550594556458110982,\n",
       " 1550594556630114316,\n",
       " 1550594557858938891,\n",
       " 1550594563596845059,\n",
       " 1550594566654402561,\n",
       " 1550594577639383040,\n",
       " 1550594575571603465,\n",
       " 1550594577723187200,\n",
       " 1550594575500197891,\n",
       " 1550594582630567936,\n",
       " 1550594585621037057,\n",
       " 1550594590180261889,\n",
       " 1550594590234869760,\n",
       " 1550594591912493056,\n",
       " 1550594597448974338,\n",
       " 1550594596878618625,\n",
       " 1550594601936994305,\n",
       " 1550594600380801025,\n",
       " 1550594601848807428,\n",
       " 1550594609738403842,\n",
       " 1550594614469484547,\n",
       " 1550594615392321536,\n",
       " 1550594615815856130,\n",
       " 1550594617480986627,\n",
       " 1550594618613440520,\n",
       " 1550594619397767168,\n",
       " 1550594623369887744,\n",
       " 1550594622535204871,\n",
       " 1550594623306964994,\n",
       " 1550594630181441537,\n",
       " 1550594639664746501,\n",
       " 1550594640893599744,\n",
       " 1550594642172944384,\n",
       " 1550594645595414529,\n",
       " 1550594645926809600,\n",
       " 1550594650125246465,\n",
       " 1550594651429691392,\n",
       " 1550594659373797377,\n",
       " 1550594659210108936,\n",
       " 1550594662217433090,\n",
       " 1550594661911339013,\n",
       " 1550594665728167936,\n",
       " 1550594672401195008,\n",
       " 1550594674448113664,\n",
       " 1550594676201328644,\n",
       " 1550594678281617408,\n",
       " 1550594677191151617,\n",
       " 1550594682425679873,\n",
       " 1550594679535804419,\n",
       " 1550594680815079426,\n",
       " 1550594678738849792,\n",
       " 1550594682039721988,\n",
       " 1550594682903826437,\n",
       " 1550594686556987393,\n",
       " 1550594690424209410,\n",
       " 1550594691703492610,\n",
       " 1550594693385408512,\n",
       " 1550594692903059456,\n",
       " 1550594698519236609,\n",
       " 1550594696270987264,\n",
       " 1550594700033376256,\n",
       " 1550594703850078209,\n",
       " 1550594704743489536,\n",
       " 1550594708837224449,\n",
       " 1550594708937875457,\n",
       " 1550594710527418369,\n",
       " 1550594711848640512,\n",
       " 1550594713878728704,\n",
       " 1550594716810547200,\n",
       " 1550594719977291778,\n",
       " 1550594720577069058,\n",
       " 1550594720509861888,\n",
       " 1550594717959725063,\n",
       " 1550594724339322881,\n",
       " 1550594720526745602,\n",
       " 1550594726906236936,\n",
       " 1550594728470740994,\n",
       " 1550594731444473857,\n",
       " 1550594732832837632,\n",
       " 1550594729817022466,\n",
       " 1550594733633855488,\n",
       " 1550594731725541378,\n",
       " 1550594736012070913,\n",
       " 1550594740315475968,\n",
       " 1550594741452083200,\n",
       " 1550594737916329985,\n",
       " 1550594742882340865,\n",
       " 1550594747638628363,\n",
       " 1550594747458265091,\n",
       " 1550594747479326722,\n",
       " 1550594749857505287,\n",
       " 1550594751359074304,\n",
       " 1550594756744462336,\n",
       " 1550594755481976832,\n",
       " 1550594757239472128,\n",
       " 1550594754915835904,\n",
       " 1550594765938429952,\n",
       " 1550594768438267911,\n",
       " 1550594772565479436,\n",
       " 1550594772083040259,\n",
       " 1550594773895057410,\n",
       " 1550594774725541889,\n",
       " 1550594776025661441,\n",
       " 1550594780979142656,\n",
       " 1550594786461192193,\n",
       " 1550594787731972098,\n",
       " 1550594788109459456,\n",
       " 1550594791125225473,\n",
       " 1550594792077287427,\n",
       " 1550594794044391429,\n",
       " 1550594792425459713,\n",
       " 1550594793075523584,\n",
       " 1550594795256659973,\n",
       " 1550594799518056449,\n",
       " 1550594796523323394,\n",
       " 1550594796984623104,\n",
       " 1550594797223682048,\n",
       " 1550594802814779392,\n",
       " 1550594803058057218,\n",
       " 1550594800881115136,\n",
       " 1550594801577463809,\n",
       " 1550594801535537157,\n",
       " 1550594806589554688,\n",
       " 1550594804962263040,\n",
       " 1550594805872353285,\n",
       " 1550594807881498626,\n",
       " 1550594815888433153,\n",
       " 1550594816605650944,\n",
       " 1550594819172564995,\n",
       " 1550594818337816576,\n",
       " 1550594818778300418,\n",
       " 1550594822989381634,\n",
       " 1550594824243482624,\n",
       " 1550594823429783563,\n",
       " 1550594825870888962,\n",
       " 1550594827213045769,\n",
       " 1550594828857139200,\n",
       " 1550594829675073542,\n",
       " 1550594830077665280,\n",
       " 1550594830685900801,\n",
       " 1550594832992706561,\n",
       " 1550594834313912325,\n",
       " 1550594834641059843,\n",
       " 1550594834540412928,\n",
       " 1550594834305585153,\n",
       " 1550594843054948352,\n",
       " 1550594845634428931,\n",
       " 1550594845852442629,\n",
       " 1550594849434484736,\n",
       " 1550594848511647745,\n",
       " 1550594853007986688,\n",
       " 1550594853964324881,\n",
       " 1550594851045007360,\n",
       " 1550594858368237573,\n",
       " 1550594854970949633,\n",
       " 1550594858741538816,\n",
       " 1550594858099818497,\n",
       " 1550594861153357826,\n",
       " 1550594866152890369,\n",
       " 1550594869953019904,\n",
       " 1550594871802699776,\n",
       " 1550594875237830661,\n",
       " 1550594876605079552,\n",
       " 1550594879192981504,\n",
       " 1550594887128694785,\n",
       " 1550594893034168328,\n",
       " 1550594894628020243,\n",
       " 1550594892996419585,\n",
       " 1550594900147802113,\n",
       " 1550594899262808066,\n",
       " 1550594902274330631,\n",
       " 1550594903884943367,\n",
       " 1550594902295298050,\n",
       " 1550594903117291520,\n",
       " 1550594902303686657,\n",
       " 1550594902995734535,\n",
       " 1550594908548993024,\n",
       " 1550594907676590080,\n",
       " 1550594910864154624,\n",
       " 1550594911468126209,\n",
       " 1550594911342297097,\n",
       " 1550594916409131012,\n",
       " 1550594915268280320,\n",
       " 1550594913997307904,\n",
       " 1550594916912402433,\n",
       " 1550594921849028608,\n",
       " 1550594921761050625,\n",
       " 1550594923069571072,\n",
       " 1550594929482731521,\n",
       " 1550594928631316482,\n",
       " 1550594931382697985,\n",
       " 1550594931235950594,\n",
       " 1550594932028628992,\n",
       " 1550594932032905219,\n",
       " 1550594934129950723,\n",
       " 1550594935841296384,\n",
       " 1550594942447271938,\n",
       " 1550594942057209858,\n",
       " 1550594944280236032,\n",
       " 1550594944615809031,\n",
       " 1550594947111424011,\n",
       " 1550594950907183105,\n",
       " 1550594966807842819,\n",
       " 1550594968888147969,\n",
       " 1550594974080712706,\n",
       " 1550594977339785216,\n",
       " 1550594979608813570,\n",
       " 1550594976618319872,\n",
       " 1550594981915680769,\n",
       " 1550594981135622144,\n",
       " 1550594984600035333,\n",
       " 1550594981437513730,\n",
       " 1550594988517605376,\n",
       " 1550594985770323968,\n",
       " 1550594985938010114,\n",
       " 1550594989939376134,\n",
       " 1550594991600373766,\n",
       " 1550594988941185025,\n",
       " 1550594991893975041,\n",
       " 1550595001327001600,\n",
       " 1550595000370708486,\n",
       " 1550595005663924224,\n",
       " 1550595006498574336,\n",
       " 1550595008776003585,\n",
       " 1550595007068913668,\n",
       " 1550595008264298496,\n",
       " 1550595011582087170,\n",
       " 1550595012676796426,\n",
       " 1550595010470576131,\n",
       " 1550595011695222790,\n",
       " 1550595017152102407,\n",
       " 1550595015226916865,\n",
       " 1550595021807689733,\n",
       " 1550595022243889154,\n",
       " 1550595019723128834,\n",
       " 1550595018922070019,\n",
       " 1550595022684389376,\n",
       " 1550595023648989185,\n",
       " 1550595023070175236,\n",
       " 1550595026677338117,\n",
       " 1550595024546668556,\n",
       " 1550595025989500928,\n",
       " 1550595026379489284,\n",
       " 1550595029726646272,\n",
       " 1550595028363497475,\n",
       " 1550595037230239770,\n",
       " 1550595037301440512,\n",
       " 1550595037330898947,\n",
       " 1550595043546861575,\n",
       " 1550595039398608900,\n",
       " 1550595046134763529,\n",
       " 1550595050501021702,\n",
       " 1550595049959956480,\n",
       " 1550595051562074113,\n",
       " 1550595063192903680,\n",
       " 1550595062433816576,\n",
       " 1550595061586567168,\n",
       " 1550595065369747457,\n",
       " 1550595071287992321,\n",
       " 1550595070033903616,\n",
       " 1550595073825439745,\n",
       " 1550595076270673920,\n",
       " 1550595074672795654,\n",
       " 1550595074307801088,\n",
       " 1550595079290642434,\n",
       " 1550595080708395012,\n",
       " 1550595089730342914,\n",
       " 1550595100597690369,\n",
       " 1550595099989606401,\n",
       " 1550595102267015168,\n",
       " 1550595098861342721,\n",
       " 1550595101058949120,\n",
       " 1550595103412068355,\n",
       " 1550595103349248006,\n",
       " 1550595103386894336,\n",
       " 1550595105807077377,\n",
       " 1550595109896568839,\n",
       " 1550595108743118849,\n",
       " 1550595112425496576,\n",
       " 1550595119103070209,\n",
       " 1550595118679396352,\n",
       " 1550595121216978954,\n",
       " 1550595119551844352,\n",
       " 1550595123486101505,\n",
       " 1550595124111052803,\n",
       " 1550595124668817413,\n",
       " 1550595131631337473,\n",
       " 1550595137159438339,\n",
       " 1550595138816196610,\n",
       " 1550595137331499008,\n",
       " 1550595138778529794,\n",
       " 1550595138799501313,\n",
       " 1550595141383208960,\n",
       " 1550595142003851264,\n",
       " 1550595141773189120,\n",
       " 1550595143799132164,\n",
       " 1550595147188011009,\n",
       " 1550595149436260357,\n",
       " 1550595151713771522,\n",
       " 1550595154406408194,\n",
       " 1550595156411404291,\n",
       " 1550595160660123654,\n",
       " 1550595164443402242,\n",
       " 1550595165227728897,\n",
       " 1550595161960644609,\n",
       " 1550595168319012865,\n",
       " 1550595173595365378,\n",
       " 1550595175864586240,\n",
       " 1550595174803324931,\n",
       " 1550595178649587712,\n",
       " 1550595179538702336,\n",
       " 1550595178674651136,\n",
       " 1550595179727523841,\n",
       " 1550595179584929794,\n",
       " 1550595186245668865,\n",
       " 1550595184919977985,\n",
       " 1550595183699529730,\n",
       " 1550595184089497600,\n",
       " 1550595185863688205,\n",
       " 1550595192096493569,\n",
       " 1550595193052823553,\n",
       " 1550595190364176384,\n",
       " 1550595191182168068,\n",
       " 1550595209746173953,\n",
       " 1550595209733488640,\n",
       " 1550595210970890242,\n",
       " 1550595209410625537,\n",
       " 1550595208022294530,\n",
       " 1550595213495832579,\n",
       " 1550595215483863040,\n",
       " 1550595219648876544,\n",
       " 1550595221448261635,\n",
       " 1550595225881640961,\n",
       " 1550595228167462914,\n",
       " 1550595229748797440,\n",
       " 1550595232026296321,\n",
       " 1550595232529584129,\n",
       " 1550595229773856776,\n",
       " 1550595232747720705,\n",
       " 1550595234467381248,\n",
       " 1550595236568748032,\n",
       " 1550595238946869248,\n",
       " 1550595239894712320,\n",
       " 1550595240083574784,\n",
       " 1550595245720625152,\n",
       " 1550595246647648256,\n",
       " 1550595249508065280,\n",
       " 1550595250862936066,\n",
       " 1550595250367991810,\n",
       " 1550595254344089601,\n",
       " 1550595258165125127,\n",
       " 1550595255812120578,\n",
       " 1550595261680222208,\n",
       " 1550595260270665729,\n",
       " 1550595260476260352,\n",
       " 1550595262162280449,\n",
       " 1550595263726854146,\n",
       " 1550595269821079552,\n",
       " 1550595274006986760,\n",
       " 1550595275923890181,\n",
       " 1550595281380642816,\n",
       " 1550595279774449664,\n",
       " 1550595286422233088,\n",
       " 1550595283037392896,\n",
       " 1550595286011092999,\n",
       " 1550595289114972160,\n",
       " 1550595288989065216,\n",
       " 1550595290591367170,\n",
       " 1550595293586022401,\n",
       " 1550595295385362435,\n",
       " 1550595295217590279,\n",
       " 1550595296304025600,\n",
       " 1550595298753380359,\n",
       " 1550595303631425536,\n",
       " 1550595299676135425,\n",
       " 1550595300330536960,\n",
       " 1550595301265776640,\n",
       " 1550595304117895175,\n",
       " 1550595305321660416,\n",
       " 1550595305938321409,\n",
       " 1550595309352505345,\n",
       " 1550595311994912768,\n",
       " 1550595312842145792,\n",
       " 1550595316574932994,\n",
       " 1550595318038806528,\n",
       " 1550595316184977408,\n",
       " 1550595318726664192,\n",
       " 1550595323336302598,\n",
       " 1550595321125711873,\n",
       " 1550595321356500995,\n",
       " 1550595325009723393,\n",
       " 1550595328113606661,\n",
       " 1550595324841959435,\n",
       " 1550595330898644992,\n",
       " 1550595333637513217,\n",
       " 1550595335122259968,\n",
       " 1550595333578784768,\n",
       " 1550595336376295425,\n",
       " 1550595339551490051,\n",
       " 1550595340172238848,\n",
       " 1550595344819535873,\n",
       " 1550595352289583104,\n",
       " 1550595355607285768,\n",
       " 1550595356530024455,\n",
       " 1550595355393359872,\n",
       " 1550595356030865408,\n",
       " 1550595364511694849,\n",
       " 1550595365329686528,\n",
       " 1550595368953544705,\n",
       " 1550595368693399568,\n",
       " 1550595367443496960,\n",
       " 1550595373282066432,\n",
       " 1550595372841566212,\n",
       " 1550595379875483650,\n",
       " 1550595382958346240,\n",
       " 1550595379699367936,\n",
       " 1550595382119485440,\n",
       " 1550595383310651392,\n",
       " 1550595383746781186,\n",
       " 1550595383717412867,\n",
       " 1550595389597929472,\n",
       " 1550595387915964419,\n",
       " 1550595390369562625,\n",
       " 1550595393926438912,\n",
       " 1550595392995213313,\n",
       " 1550595397764145152,\n",
       " 1550595396522614786,\n",
       " 1550595397546119168,\n",
       " 1550595402579283968,\n",
       " 1550595403984281605,\n",
       " 1550595404777111553,\n",
       " 1550595404693180417,\n",
       " 1550595404756041731,\n",
       " 1550595407570509826,\n",
       " 1550595409944387590,\n",
       " 1550595410422644736,\n",
       " 1550595415975886850,\n",
       " 1550595417276129282,\n",
       " 1550595425085816832,\n",
       " 1550595424419024898,\n",
       " 1550595432010637312,\n",
       " 1550595434489470977,\n",
       " 1550595437001953280,\n",
       " 1550595435328307201,\n",
       " 1550595444480397312,\n",
       " 1550595442416750597,\n",
       " 1550595443511463937,\n",
       " 1550595449161121792,\n",
       " 1550595449647730688,\n",
       " 1550595451803533312,\n",
       " 1550595453787557889,\n",
       " 1550595453359722499,\n",
       " 1550595454932492290,\n",
       " 1550595455045832705,\n",
       " 1550595458837450762,\n",
       " 1550595462465523726,\n",
       " 1550595465086992387,\n",
       " 1550595470199775232,\n",
       " 1550595473135869958,\n",
       " 1550595473446260738,\n",
       " 1550595475212050432,\n",
       " 1550595478944944128,\n",
       " 1550595476902264832,\n",
       " 1550595477128757249,\n",
       " 1550595479825678337,\n",
       " 1550595482304618496,\n",
       " 1550595481029558278,\n",
       " 1550595484405866498,\n",
       " 1550595485412499475,\n",
       " 1550595489388716033,\n",
       " 1550595494505750529,\n",
       " 1550595497827639301,\n",
       " 1550595498607841280,\n",
       " 1550595499006349312,\n",
       " 1550595501443129367,\n",
       " 1550595507852120066,\n",
       " 1550595508787347465,\n",
       " 1550595512537174019,\n",
       " 1550595510813212674,\n",
       " 1550595511694098432,\n",
       " 1550595512885190658,\n",
       " 1550595515133431810,\n",
       " 1550595515762593792,\n",
       " 1550595517528379392,\n",
       " 1550595520443326465,\n",
       " 1550595524289609728,\n",
       " 1550595522154696710,\n",
       " 1550595526369939456,\n",
       " 1550595527024283648,\n",
       " 1550595527913480202,\n",
       " 1550595532212654097,\n",
       " 1550595532158308352,\n",
       " 1550595534460796932,\n",
       " 1550595537287741440,\n",
       " 1550595538965389313,\n",
       " 1550595538428518404,\n",
       " 1550595540919803904,\n",
       " 1550595542727753732,\n",
       " 1550595543524597760,\n",
       " 1550595549493084163,\n",
       " 1550595547073052673,\n",
       " 1550595551481274368,\n",
       " 1550595553192443904,\n",
       " 1550595551569272834,\n",
       " 1550595553226117120,\n",
       " 1550595552454344705,\n",
       " 1550595552789893120,\n",
       " 1550595557701419008,\n",
       " 1550595563032387585,\n",
       " 1550595562877190144,\n",
       " 1550595562101260309,\n",
       " 1550595567562231810,\n",
       " 1550595565423132674,\n",
       " 1550595565066518528,\n",
       " 1550595567813894144,\n",
       " 1550595570447880193,\n",
       " 1550595578098237441,\n",
       " 1550595578807083015,\n",
       " 1550595579637649409,\n",
       " 1550595576647110663,\n",
       " 1550595581256531969,\n",
       " 1550595581738983425,\n",
       " 1550595582707777536,\n",
       " 1550595588185591811,\n",
       " 1550595584536477699,\n",
       " 1550595585903939589,\n",
       " 1550595591050231809,\n",
       " 1550595596804833281,\n",
       " 1550595595932520449,\n",
       " 1550595597710893056,\n",
       " 1550595599279554561,\n",
       " 1550595605898137603,\n",
       " 1550595607873699840,\n",
       " 1550595608137924608,\n",
       " 1550595609593348098,\n",
       " 1550595611803656195,\n",
       " 1550595613997387777,\n",
       " 1550595613225635841,\n",
       " 1550595615976988674,\n",
       " 1550595619689037830,\n",
       " 1550595618665598983,\n",
       " 1550595626781605890,\n",
       " 1550595630778798081,\n",
       " 1550595627834302464,\n",
       " 1550595631550545924,\n",
       " 1550595637888032768,\n",
       " 1550595640475979776,\n",
       " 1550595642929647618,\n",
       " 1550595642514366464,\n",
       " 1550595641629462531,\n",
       " 1550595642560577537,\n",
       " 1550595643302977538,\n",
       " 1550595645991444481,\n",
       " 1550595649720258562,\n",
       " 1550595652207394816,\n",
       " 1550595650529755137,\n",
       " 1550595653889396736,\n",
       " 1550595654975721473,\n",
       " 1550595653906141191,\n",
       " 1550595654732468226,\n",
       " 1550595662940610560,\n",
       " 1550595667097255937,\n",
       " 1550595668573667332,\n",
       " 1550595665633353729,\n",
       " 1550595668569460737,\n",
       " 1550595672075902983,\n",
       " 1550595669810991105,\n",
       " 1550595670607896578,\n",
       " 1550595675653607425,\n",
       " 1550595673963331584,\n",
       " 1550595674672173058,\n",
       " 1550595677947920385,\n",
       " 1550595677239009282,\n",
       " 1550595680435159040,\n",
       " 1550595677796925440,\n",
       " 1550595678367371268,\n",
       " 1550595682779779080,\n",
       " 1550595684012802051,\n",
       " 1550595685761908738,\n",
       " 1550595689146638336,\n",
       " 1550595690702798849,\n",
       " 1550595692447600650,\n",
       " 1550595690736254978,\n",
       " 1550595692011393024,\n",
       " 1550595692074307585,\n",
       " 1550595694104305664,\n",
       " 1550595697040293889,\n",
       " 1550595697816264704,\n",
       " 1550595697946279938,\n",
       " 1550595703692484609,\n",
       " 1550595702958575616,\n",
       " 1550595703730225156,\n",
       " 1550595704611028995,\n",
       " 1550595708243382273,\n",
       " 1550595714786496514,\n",
       " 1550595715126157313,\n",
       " 1550595717244280832,\n",
       " 1550595716363550722,\n",
       " 1550595719018545152,\n",
       " 1550595726845116418,\n",
       " 1550595727147024384,\n",
       " 1550595727784640514,\n",
       " 1550595731265929218,\n",
       " 1550595734814294016,\n",
       " 1550595737746128896,\n",
       " 1550595739830689793,\n",
       " 1550595739797127168,\n",
       " 1550595739880914951,\n",
       " 1550595740476514304,\n",
       " 1550595743597166596,\n",
       " 1550595745589641216,\n",
       " 1550595745337712645,\n",
       " 1550595746461786112,\n",
       " 1550595746537291777,\n",
       " 1550595751813816321,\n",
       " 1550595752459735041,\n",
       " 1550595757895565312,\n",
       " 1550595761280372736,\n",
       " 1550595759296610304,\n",
       " 1550595762509287437,\n",
       " 1550595762576302081,\n",
       " 1550595767576006665,\n",
       " 1550595766674243584,\n",
       " 1550595764585390080,\n",
       " 1550595771204083715,\n",
       " 1550595772097380358,\n",
       " 1550595776379748354,\n",
       " 1550595776866406400,\n",
       " 1550595775465496579,\n",
       " 1550595773871673349,\n",
       " 1550595783636013057,\n",
       " 1550595787498848257,\n",
       " 1550595787272462336,\n",
       " 1550595793471651840,\n",
       " 1550595792242704386,\n",
       " 1550595796684476416,\n",
       " 1550595799050059782,\n",
       " 1550595800597659653,\n",
       " 1550595801440821250,\n",
       " 1550595801948344320,\n",
       " 1550595800668962816,\n",
       " 1550595805622534156,\n",
       " 1550595811519651840,\n",
       " 1550595813075783680,\n",
       " 1550595811586752513,\n",
       " 1550595811607826438,\n",
       " 1550595815718232067,\n",
       " 1550595816624209920,\n",
       " 1550595815806308352,\n",
       " 1550595817525870592,\n",
       " 1550595826212372481,\n",
       " 1550595825033773057,\n",
       " 1550595826669453312,\n",
       " 1550595827533496323,\n",
       " 1550595826635915267,\n",
       " 1550595826388553728,\n",
       " 1550595832931618818,\n",
       " 1550595832583430150,\n",
       " 1550595832361193472,\n",
       " 1550595839218917381,\n",
       " 1550595837637656579,\n",
       " 1550595842217762818,\n",
       " 1550595842599534595,\n",
       " 1550595848014290944,\n",
       " 1550588958026997760,\n",
       " 1550588968726663172,\n",
       " 1550588969800404994,\n",
       " 1550588966847619072,\n",
       " 1550588969485848578,\n",
       " 1550588970664337408,\n",
       " 1550588973176819712,\n",
       " 1550588973449453568,\n",
       " 1550588976502870018,\n",
       " 1550588977777967106,\n",
       " 1550588977803034630,\n",
       " 1550588979455692800,\n",
       " 1550588983154991105,\n",
       " 1550588985147269129,\n",
       " 1550588986581737473,\n",
       " 1550588990180528136,\n",
       " 1550588987881947136,\n",
       " 1550588990331437058,\n",
       " 1550588990742462464,\n",
       " 1550588995083636738,\n",
       " 1550588993728909314,\n",
       " 1550588998355124224,\n",
       " 1550588997881466880,\n",
       " 1550588997893865472,\n",
       " 1550588996891430912,\n",
       " 1550588998325678080,\n",
       " 1550589003388358657,\n",
       " 1550589001404391424,\n",
       " 1550589002935418880,\n",
       " 1550589002947911681,\n",
       " 1550589005514919943,\n",
       " 1550589005615570945,\n",
       " 1550589007611961349,\n",
       " 1550589010795438081,\n",
       " 1550589009864409100,\n",
       " 1550589008824225795,\n",
       " 1550589011730874371,\n",
       " 1550589008589225985,\n",
       " 1550589012993363973,\n",
       " 1550589015090466820,\n",
       " 1550589022640160775,\n",
       " 1550589024389271554,\n",
       " 1550589027723649025,\n",
       " 1550589033604124674,\n",
       " 1550589035613134851,\n",
       " 1550589036892413955,\n",
       " 1550589037391536128,\n",
       " 1550589039866159106,\n",
       " 1550589041317257216,\n",
       " 1550589039450923011,\n",
       " 1550589041137123330,\n",
       " 1550589038645727234,\n",
       " 1550589045285289984,\n",
       " 1550589045444644865,\n",
       " 1550589044471521284,\n",
       " 1550589045759217665,\n",
       " 1550589043129421824,\n",
       " 1550589047873179648,\n",
       " 1550589053300604929,\n",
       " 1550589052709212162,\n",
       " 1550589051161427968,\n",
       " 1550589053715841027,\n",
       " 1550589051564167168,\n",
       " 1550589051237015559,\n",
       " 1550589050784022534,\n",
       " 1550589050985357312,\n",
       " 1550589054554877953,\n",
       " 1550589056211353603,\n",
       " 1550589056240721921,\n",
       " 1550589056635076608,\n",
       " 1550589057083777025,\n",
       " 1550589057092263939,\n",
       " 1550589058996379648,\n",
       " 1550589060368007169,\n",
       " 1550589059436879879,\n",
       " 1550589058509930508,\n",
       " 1550589060930052097,\n",
       " 1550589059772334086,\n",
       " 1550589058702839815,\n",
       " 1550589064423899136,\n",
       " 1550589063362666498,\n",
       " 1550589063450841088,\n",
       " 1550589062972641280,\n",
       " 1550589064230862848,\n",
       " 1550589073232113664,\n",
       " 1550589076176265216,\n",
       " 1550589078944497664,\n",
       " 1550589082249617410,\n",
       " 1550589081020669954,\n",
       " 1550589082132152320,\n",
       " 1550589082220249088,\n",
       " 1550589081771458560,\n",
       " 1550589087698092033,\n",
       " 1550589085990936578,\n",
       " 1550589084367814658,\n",
       " 1550589088566214660,\n",
       " 1550589088570417161,\n",
       " 1550589093003902976,\n",
       " 1550589095264518147,\n",
       " 1550589095616946177,\n",
       " 1550589094807339009,\n",
       " 1550589095277199366,\n",
       " 1550589099563704323,\n",
       " 1550589098125152259,\n",
       " 1550589098959708161,\n",
       " 1550589102818574343,\n",
       " 1550589103208554496,\n",
       " 1550589104059981825,\n",
       " 1550589108283752449,\n",
       " 1550589106564087809,\n",
       " 1550589106631188481,\n",
       " 1550589106803150849,\n",
       " 1550589109202292736,\n",
       " 1550589110699573257,\n",
       " 1550589113283248129,\n",
       " 1550589114566807552,\n",
       " 1550589116244525057,\n",
       " 1550589118710775809,\n",
       " 1550589120413671425,\n",
       " 1550589122699485185,\n",
       " 1550589126713516033,\n",
       " 1550589135857106945,\n",
       " 1550589136066826240,\n",
       " 1550589138000351232,\n",
       " 1550589134040928258,\n",
       " 1550589135966142466,\n",
       " 1550589138650505218,\n",
       " 1550589141376712704,\n",
       " 1550589141771075587,\n",
       " 1550589138813976576,\n",
       " 1550589138554036224,\n",
       " 1550589145042587649,\n",
       " 1550589145541758978,\n",
       " 1550589146338582530,\n",
       " 1550589151728340992,\n",
       " 1550589154974654465,\n",
       " 1550589155972882434,\n",
       " 1550589155796738053,\n",
       " 1550589157277319169,\n",
       " 1550589155901571072,\n",
       " 1550589157302571016,\n",
       " 1550589157331898377,\n",
       " 1550589161807257603,\n",
       " 1550589163157815296,\n",
       " 1550589160687374338,\n",
       " 1550589161970827265,\n",
       " 1550589163568783367,\n",
       " 1550589163782787072,\n",
       " 1550589168673243137,\n",
       " 1550589177284141057,\n",
       " 1550589178458537986,\n",
       " 1550589180807356416,\n",
       " 1550589180107014147,\n",
       " 1550589180396425216,\n",
       " 1550589181239386112,\n",
       " 1550589182472593409,\n",
       " 1550589186696249357,\n",
       " 1550589185400209408,\n",
       " 1550589189191831557,\n",
       " 1550589192136232969,\n",
       " 1550589188973674499,\n",
       " 1550589195030233090,\n",
       " 1550589196020088833,\n",
       " 1550589196770983937,\n",
       " 1550589199006457858,\n",
       " 1550589197592977408,\n",
       " 1550589198868037639,\n",
       " 1550589198448705537,\n",
       " 1550589201871167488,\n",
       " 1550589210624770050,\n",
       " 1550589209332916224,\n",
       " 1550589215536300032,\n",
       " 1550589215981051904,\n",
       " 1550589219973873664,\n",
       " 1550589223190892545,\n",
       " 1550589225694904325,\n",
       " 1550589222360432640,\n",
       " 1550589225254490113,\n",
       " 1550589224835059713,\n",
       " 1550589233609449478,\n",
       " 1550589233961713664,\n",
       " 1550589233215275008,\n",
       " 1550589237443133441,\n",
       " 1550589234909700097,\n",
       " 1550589238453968906,\n",
       " ...]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = get_missing_tweet_ids_from_file('/home/esener/thesis/Thesis/data/output/stream_tweetids_2022-07_splitted/output_stream_tweetids_2022-07_0.csv')\n",
    "list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from typing import Dict, List, Any\n",
    "import logging\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "import os\n",
    "import re\n",
    "from tweety import Twitter\n",
    "# Last function in the process, which converts dataframe to csv file\n",
    "def custom_write_csv(df: pd.DataFrame, output_path: str, data_name: str):\n",
    "    file_name = os.path.join(output_path, f'output_{data_name}.csv')\n",
    "    try:\n",
    "        df.to_csv(file_name, mode='a', index=False, header=False)\n",
    "    except Exception as e:\n",
    "        logging.error(f'Failed to write chunk {e}')\n",
    "        \n",
    "\n",
    "# Processes a chunk of data. The function is used in process_data_in_parallel, which chunks the given df into 10 chunks\n",
    "def process_chunk(app, df_chunk: pd.DataFrame, output_path: str, data_name: str):\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df_chunk.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        try:\n",
    "            api_response = fetch_additional_info(app, tweet_id=row_dict['tweet_id'])\n",
    "            additional_info = parse_api_response(api_response)\n",
    "            row_dict.update(additional_info)\n",
    "        except Exception as e: \n",
    "            logging.error(f'Failed to process chunk {e}')\n",
    "\n",
    "        results.append(row_dict)\n",
    "    result_df = pd.DataFrame(results)        \n",
    "    custom_write_csv(result_df, output_path, data_name)  # Pass output_path and data_name to custom_write_csv\n",
    "\n",
    "# Used for parallel processing, main function here is process_chunk\n",
    "def process_data_in_parallel(app, df, output_path: str, data_name: str):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        chunks = np.array_split(df, 10)\n",
    "        # Use a lambda function to pass the output_path and data_name arguments to process_chunk\n",
    "        executor.map(lambda chunk: process_chunk(app, chunk, output_path, data_name), chunks)\n",
    "\n",
    "# processes a file, which is written for .txt, calls process_data_in_parallel\n",
    "def process_file(file_path, output_path):\n",
    "    app = Twitter(\"session\")\n",
    "    logging.info(f'Processing file path: {file_path}')\n",
    "    # Extract data_name from the file path\n",
    "    data_name = os.path.basename(file_path).replace('.txt', '')\n",
    "    \n",
    "    # Read txt file and convert it to DataFrame\n",
    "    with open(file_path, 'r') as file:\n",
    "        tweet_ids = [int(line.strip()) for line in file]\n",
    "    df = pd.DataFrame(tweet_ids, columns=['tweet_id'])\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Write the header to the output file\n",
    "    output_file = os.path.join(output_path, f'output_{data_name}.csv')\n",
    "    header_df = pd.DataFrame(columns=['tweet_id', 'tweet_type', 'hashtags', 'mentions', 'lang', 'favorite_count', 'created_at', 'text', 'parent_tweet_id'])\n",
    "    header_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Process each chunk in parallel\n",
    "    process_data_in_parallel(app, df, output_path, data_name)\n",
    "\n",
    "\n",
    "def extract_number(filename):\n",
    "    # Regular expression to match a sequence of digits\n",
    "    match = re.search(r'_(\\d+)\\.txt$', filename)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "def process_all_files_in_folder(folder_path, output_folder_path, start_from_file=0):\n",
    "    # Get all files in folder_path that end with .txt\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "    # Sort files based on the numeric part of the filename\n",
    "    sorted_files = sorted(files, key=extract_number)\n",
    "    \n",
    "    for index, file_name in enumerate(sorted_files, start=0):  # start enumeration from 0 for human-readable file numbers\n",
    "        # Skip files before the 14th file\n",
    "        if index < start_from_file:\n",
    "            continue\n",
    "        \n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        logging.info(f'Processing file: {file_name}')\n",
    "        process_file(file_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = '/home/esener/thesis/Thesis/data/testFolder'\n",
    "output_folder_path = '../data/output/testFolder'\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder_path, exist_ok=True)  \n",
    "process_all_files_in_folder(input_folder_path, output_folder_path, start_from_file=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sample of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2023-06': 38980,\n",
       " '2023-05': 155947,\n",
       " '2023-04': 99890,\n",
       " '2023-03': 208955,\n",
       " '2023-02': 52179,\n",
       " '2023-01': 19034,\n",
       " '2022-12': 39119,\n",
       " '2022-11': 29857,\n",
       " '2022-10': 11141,\n",
       " '2022-09': 11279,\n",
       " '2022-08': 9777,\n",
       " '2022-07': 9743}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_collected_tweets = 67000000  # Total number of collected tweets\n",
    "desired_sample_size = 700000  # Total sample size you want\n",
    "\n",
    "# Proportions for each month\n",
    "proportions = {\n",
    "    '2023-06': 3731038,\n",
    "    '2023-05': 14926446,\n",
    "    '2023-04': 9560979,\n",
    "    '2023-03': 20000000, # reduced\n",
    "    '2023-02': 4994288,\n",
    "    '2023-01': 1821902,\n",
    "    '2022-12': 3744285,\n",
    "    '2022-11': 2857745,\n",
    "    '2022-10': 1066428,\n",
    "    '2022-09': 1079652,\n",
    "    '2022-08': 935894,\n",
    "    '2022-07': 932608,\n",
    "    # ... add other months\n",
    "}\n",
    "\n",
    "# Calculate the number of tweets to sample from each month\n",
    "sample_sizes = {month: int((count / total_collected_tweets) * desired_sample_size) for month, count in proportions.items()}\n",
    "sample_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tweets(file_path, num_samples):\n",
    "    df = pd.read_csv(file_path, usecols=['tweet_id', 'text', 'tweet_type'])\n",
    "    # Filter for non-null and length > 10\n",
    "    filtered_df = df.dropna(subset=['text']).loc[df['text'].str.len() > 10]\n",
    "    return filtered_df.sample(n=num_samples, replace=False) if len(filtered_df) >= num_samples else filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Get a list of all CSV files\n",
    "csv_files = glob.glob('../data/output/**/*.csv', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1500.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1901.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1958.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_889.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1980.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1047.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1682.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_234052/2419588190.py:2: DtypeWarning: Columns (1,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, usecols=['tweet_id', 'text', 'tweet_type'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_2585.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_909.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_675.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-03_splitted/output_streamV2_tweetnet_2023-03_1109.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetids_2023-03_splitted/output_streamV2_tweetids_2023-03_675.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_473.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_1431.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_1397.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_896.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-04_splitted/output_streamV2_tweetnet_2023-04_719.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/stream_tweetids_2023-01_splitted/output_stream_tweetids_2023-01_846.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetids_2023-05_splitted/output_streamV2_tweetids_2023-05_1319.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_1473.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_1307.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_271.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/streamV2_tweetnet_2023-05_splitted/output_streamV2_tweetnet_2023-05_2027.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/stream_tweetids_2022-11_splitted/output_stream_tweetids_2022-11_75.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/stream_tweetids_2022-11_splitted/output_stream_tweetids_2022-11_420.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/missing_tweets/2_stream_tweetids_2022-09_splitted/output_output_stream_tweetids_2022-09_448.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/missing_tweets/2_stream_tweetids_2022-09_splitted/output_output_stream_tweetids_2022-09_800.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_176.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_112.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n",
      "Error sampling from file ../data/output/stream_tweetids_2022-09_splitted/output_stream_tweetids_2022-09_177.csv: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to extract month from file path\n",
    "def extract_month(file_path):\n",
    "    match = re.search(r'(\\d{4}-\\d{2})', file_path)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Group files by month\n",
    "files_by_month = defaultdict(list)\n",
    "for file in csv_files:\n",
    "    month = extract_month(file)\n",
    "    if month:\n",
    "        files_by_month[month].append(file)\n",
    "\n",
    "# Sampling process\n",
    "sampled_tweets = []\n",
    "for month, files in files_by_month.items():\n",
    "    for file in files:\n",
    "        try:\n",
    "            num_samples = sample_sizes.get(month, 0) // len(files)\n",
    "            sampled_tweets.append(sample_tweets(file, num_samples))\n",
    "        except Exception as e:\n",
    "            print(f\"Error sampling from file {file}: {e}\")\n",
    "\n",
    "# Concatenate all sampled tweets into one DataFrame\n",
    "sampled_tweets_df = pd.concat(sampled_tweets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668277"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sampled_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_tweets_df.to_csv('tweet_sample.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
